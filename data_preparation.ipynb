{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "We'll use the mountain list we have to create labels from sentences"
      ],
      "metadata": {
        "id": "3ZSnxTCnm7hY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVstGVbHfUSJ",
        "outputId": "1bef95a4-2b8f-4025-edda-61ef51c3075a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mountain_list = pd.read_csv(\"/content/mountains.csv\")\n",
        "sentences = pd.read_csv(\"/content/all_sentences.csv\")\n",
        "print(sentences.iloc[:, 0].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7ws88begNb0",
        "outputId": "0bd7f253-ac2d-45e3-bd4f-ebeef62780b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0         I am not Mount Everest - to be climbed upon!\n",
            "1    Lack of awareness of waste problem on Mount Ev...\n",
            "2    K2's recent CODiE Award for \"Best Asset Manage...\n",
            "3    Each content type (K2, Hikashop...) can be con...\n",
            "4    Vitamin K2 is needed for normal blood coagulat...\n",
            "Name: Mount Everest - the international name of the world's highest summit., dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We tokenize the sentences and create tags for the target variable"
      ],
      "metadata": {
        "id": "tePj5N7Nrcg4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_mountain_patterns(mountain_names):\n",
        "    patterns = []\n",
        "    for name in mountain_names:\n",
        "        words = name.lower().split()\n",
        "        if len(words) > 1:\n",
        "            patterns.append(tuple(words))\n",
        "        else:\n",
        "            patterns.append(words[0])\n",
        "    return patterns\n",
        "\n",
        "def sentence_to_iob(sentence, mountain_patterns):\n",
        "    tokens = nltk.tokenize.word_tokenize(sentence)\n",
        "    lower_tokens = [token.lower() for token in tokens]\n",
        "    iob_tags = ['O'] * len(tokens)\n",
        "\n",
        "    for i in range(len(tokens)):\n",
        "        for pattern in mountain_patterns:\n",
        "            if isinstance(pattern, tuple):\n",
        "                if i + len(pattern) <= len(lower_tokens):\n",
        "                    if tuple(lower_tokens[i:i+len(pattern)]) == pattern:\n",
        "                        iob_tags[i] = 'B-MOUNTAIN'\n",
        "                        for j in range(1, len(pattern)):\n",
        "                            iob_tags[i+j] = 'I-MOUNTAIN'\n",
        "            elif lower_tokens[i] == pattern:\n",
        "                iob_tags[i] = 'B-MOUNTAIN'\n",
        "\n",
        "    return tokens, iob_tags\n",
        "\n",
        "#Read the CSV files\n",
        "mountain_list = pd.read_csv(\"/content/mountains.csv\")\n",
        "sentences = pd.read_csv(\"/content/all_sentences.csv\")\n",
        "\n",
        "#Mountain names are in the first(and only) column of mountains.csv\n",
        "mountain_names = mountain_list.iloc[:, 0].tolist()\n",
        "\n",
        "# Create mountain patterns\n",
        "mountain_patterns = create_mountain_patterns(mountain_names)\n",
        "print(\"Mountain patterns created.\")\n",
        "\n",
        "results = []\n",
        "\n",
        "# Process each sentence\n",
        "for sentence in sentences.iloc[:, 0]:\n",
        "    tokens, iob_tags = sentence_to_iob(sentence, mountain_patterns)\n",
        "    token_sentence = ' '.join([f\"{token}\" for token in tokens])\n",
        "    annotation = ' '.join([f\"{tag}\" for tag in iob_tags])\n",
        "    results.append({'Tokens': token_sentence, 'Tagged Sentence': annotation})\n",
        "\n",
        "# Create the DataFrame\n",
        "df = pd.DataFrame(results)\n",
        "\n",
        "print(df.head())\n",
        "df.to_csv(\"/content/sentences_annotation.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPNOSB0xoP-9",
        "outputId": "dafce2b0-f698-4611-d831-308bebf54d4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mountain patterns created.\n",
            "                                              Tokens  \\\n",
            "0      I am not Mount Everest - to be climbed upon !   \n",
            "1  Lack of awareness of waste problem on Mount Ev...   \n",
            "2  K2 's recent CODiE Award for `` Best Asset Man...   \n",
            "3  Each content type ( K2 , Hikashop ... ) can be...   \n",
            "4  Vitamin K2 is needed for normal blood coagulat...   \n",
            "\n",
            "                                     Tagged Sentence  \n",
            "0            O O O B-MOUNTAIN I-MOUNTAIN O O O O O O  \n",
            "1              O O O O O O O B-MOUNTAIN I-MOUNTAIN O  \n",
            "2  B-MOUNTAIN O O O O O O O O O O O O O O O O O O...  \n",
            "3       O O O O B-MOUNTAIN O O O O O O O O O O O O O  \n",
            "4  O B-MOUNTAIN O O O O O O O O O O O O O O O O O...  \n",
            "                                              Tokens  \\\n",
            "0      I am not Mount Everest - to be climbed upon !   \n",
            "1  Lack of awareness of waste problem on Mount Ev...   \n",
            "2  K2 's recent CODiE Award for `` Best Asset Man...   \n",
            "3  Each content type ( K2 , Hikashop ... ) can be...   \n",
            "4  Vitamin K2 is needed for normal blood coagulat...   \n",
            "\n",
            "                                     Tagged Sentence  \n",
            "0            O O O B-MOUNTAIN I-MOUNTAIN O O O O O O  \n",
            "1              O O O O O O O B-MOUNTAIN I-MOUNTAIN O  \n",
            "2  B-MOUNTAIN O O O O O O O O O O O O O O O O O O...  \n",
            "3       O O O O B-MOUNTAIN O O O O O O O O O O O O O  \n",
            "4  O B-MOUNTAIN O O O O O O O O O O O O O O O O O...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we have it, now we remove the random sentences that can happen occasionaly with example sentences. We do it by removing all rows, whose annotation does not have a named entity"
      ],
      "metadata": {
        "id": "KSSYvuSNruqW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mask = df['Tagged Sentence'].apply(lambda x: 'B-MOUNTAIN' in x)\n",
        "df_filtered = df[mask]\n",
        "df_filtered = df_filtered.reset_index(drop=True)\n",
        "df_filtered.to_csv(\"/content/filtered_sentences_annotation.csv\")"
      ],
      "metadata": {
        "id": "RSLMShfrr6Nk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We save it to csv, and get ready to start our model"
      ],
      "metadata": {
        "id": "OS6iFfr1sC_c"
      }
    }
  ]
}